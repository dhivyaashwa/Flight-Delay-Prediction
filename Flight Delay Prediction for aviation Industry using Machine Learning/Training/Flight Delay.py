# -*- coding: utf-8 -*-
"""Welcome to Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math
import tensorflow
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn import model_selection
from sklearn.neural_network import MLPClassifier

#Read the dataset
dataset = pd.read_csv("/content/flightdata (3).csv")
dataset.head()

dataset.info()

#removing a last column
dataset = dataset.drop('Unnamed: 25', axis=1)
dataset.info()

#retrieve need dataset
dataset = dataset[["FL_NUM", "MONTH", "DAY_OF_MONTH", "DAY_OF_WEEK", "ORIGIN", "DEST", "CRS_ARR_TIME", "DEP_DEL15", "ARR_DEL15"]]
dataset.isnull().sum()#retrieve need dataset
dataset = dataset[["FL_NUM", "MONTH", "DAY_OF_MONTH", "DAY_OF_WEEK", "ORIGIN", "DEST", "CRS_ARR_TIME", "DEP_DEL15", "ARR_DEL15"]]
dataset.isnull().sum()

dataset[dataset.isnull().any(axis=1)].head(10)

dataset['DEP_DEL15'].mode()

#changing null values
dataset = dataset.fillna({"ARR_DEL15" : 1})
dataset = dataset.fillna({"DEP_DEL15" : 0})
dataset.iloc[177:185]

#convert CRS_ARR_TIME
for index, row in dataset.iterrows():
    dataset.loc[index, 'CRS_ARR_TIME'] = math.floor(row['CRS_ARR_TIME'] / 100)
dataset.head()

#convert DEST & ORIGIN using LabelEncoder
le = LabelEncoder()
dataset['DEST'] = le.fit_transform(dataset['DEST'])
dataset['ORIGIN'] = le.fit_transform(dataset['ORIGIN'])

dataset.head()

dataset["ORIGIN"].unique()

dataset.iloc[:,8:9]

#TASK 3
#descriptive analysis
data = pd.read_csv("/content/flightdata (3).csv")
data.describe()

#univariate analysis
sns.distplot(data.MONTH)

#bivariate analysis
sns.scatterplot(x='ARR_DELAY', y='ARR_DEL15', data=data)

sns.catplot(x='ARR_DEL15', y='ARR_DELAY', kind='bar', data=data)

#multivariate analysis
sns.heatmap(dataset.corr())

#splitting data into dependent & independent
x = dataset.iloc[:, 0:8].values
y = dataset.iloc[:, 8:9].values
x

y

x.shape

y.shape

#OneHotEncoder
oh = OneHotEncoder()
z = oh.fit_transform(x[:,4:5]).toarray()
t = oh.fit_transform(x[:,5:6]).toarray()
#x = np.delete(x,[4,7],axis=1)

z

t

x = np.delete(x, [4,5], axis=1)

x.shape

x = np.concatenate((t,z,x), axis=1)

x.shape

dataset=pd.get_dummies(dataset,columns=['ORIGIN','DEST'])
dataset.head()

#Splitting data into train and test
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)

x_test.shape

x_train.shape

y_test.shape

y_train.shape

#Scalling the data
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

#TASK 4 - Model building
#Decision tree model
classifier = DecisionTreeClassifier(random_state = 0)
classifier.fit(x_train, y_train)

decisiontree = classifier.predict(x_test)
decisiontree

#check accuracy
desacc = accuracy_score(y_test, decisiontree)
desacc

#Random forest model
rfc=RandomForestClassifier(n_estimators=10,criterion='entropy')
rfc.fit(x_train,y_train)

y_predict=rfc.predict(x_test)
y_predict

#ANN model
from keras.api._v2.keras import activations
#creating ANN skleton view
classification = Sequential()
classification.add(Dense(30,activation='relu'))
classification.add(Dense(128,activation='relu'))
classification.add(Dense(64,activation='relu'))
classification.add(Dense(32,activation='relu'))
classification.add(Dense(1,activation='sigmoid'))

#compilling the ANN model
classification.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

#Training the model
classification.fit(x_train, y_train, batch_size=4, validation_split=0.2, epochs=100)

#Activity 2: Test the model
#Decision tree
y_pred=classifier.predict([[129,99,1,0,0,1,0,1,1,1,0,1,1,1,1,1]])
y_pred

#RandomForest
y_pred=rfc.predict([[129,99,1,0,0,1,0,1,1,1,0,1,1,1,1,1]])
y_pred

classification.save('flight.h5')

#Testing the model
y_pred=classification.predict(x_test)
y_pred

y_pred = (y_pred>0.5)
y_pred

def predict_exit(sample_value):
  #convert list to numpy array
  sample_value=np.array(sample_value)
  #Reshape because sample_value is contains only 1 value
  sample_value=sample_value.reshape(1,-1)
  #Feature scaling 
  sample_value=sc.transform(sample_value)
  return classifier.predict(sample_value)

test=classification.predict([[1,1,121.000000,36.0,0,0,1,0,1,1,1,1,1,1,1,1,]])
if test==1:
  print('Prediction: Chance Of Delay')
else:
  print('Prediction: No Chance Of Delay')

#Task-5 Performance Testing & Hyperparameter Tuning
#Compare the model

def classification_report():
  dfs=[]
  models=[
        ('RF',RandomForestClassifier()),
        ('DecisionTree',DecisionTreeClassifier()),
        ('ANN',MLPClassifier())
      ]
  results=[]
  names=[]
  scoring=['accuracy','precision_weighted','recall_weighted','f1_weighted','roc_auc']
  target_names=['no delay','delay']
  for name,model in models:
    kfold=model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)
    cv_results=model_selection.cross_validate(model,x_train, y_train, cv=kfold, scoring=scoring)
    clf=model.fit(x_train, y_train)
    y_pred=clf.predict(x_test)
    print(name)
    print(classification_report(y_test,y_pred,target_names=target_names))
    results.append(cv_results)
    names.append(name)
    this_df=pd.DataFrame(cv_results)
    this_df['models']=name
    dfs.append(this_df)
    final=pd.concat(dfs,ignore_index=True)
  return final

#RandomForest Accuracy
print('Training Accuracy: ',accuracy_score(y_pred, y_predict))
print('Testing Accuracy: ',accuracy_score(y_test, y_predict))

# Making the Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict)
cm

# Accuracy score of decision tree
desacc = accuracy_score(y_test,decisiontree)
desacc

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,decisiontree)
cm

from sklearn.metrics import accuracy_score,classification_report
score = accuracy_score(y_pred,y_test)
print('The accuracy for ANN model is: {}%'.format(score*100))

# Making the Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
cm

# Activity 2: Hyperparameter tuning
# giving some parameters
parameters = {
    'n_estimators' : [1,20,30,55,68,74,90,120,115],
    'criterion' : ['gini', 'entropy'],
    'max_features' : ['auto', 'sqrt', 'log2'],
    'max_depth' : [2,5,8,10], 'verbose' : [1,2,3,4,6,8,9,10]
}

# Performing the randomized cv
from sklearn.model_selection import RandomizedSearchCV
RCV = RandomizedSearchCV(estimator = rfc, param_distributions = parameters, cv = 10, n_iter = 4)

RCV.fit(x_train, y_train)

# Getting the best parameters

bt_params = RCV.best_params_
bt_score = RCV.best_score_

bt_params

bt_score

model = RandomForestClassifier(verbose = 10, n_estimators = 120, max_features = 'log2', max_depth = 10, criterion = 'entropy')
RCV.fit(x_train, y_train)

y_predict_rf = RCV.predict(x_test)

RFC = accuracy_score(y_test, y_predict_rf)
RFC

import pickle
pickle.dump(RCV, open('flight.pkl', 'wb'))

# import sklearn.metrics as metrics
# fpr1, tpr1, threshold1 = metrics.roc_curve(y_test, decisiontree)
# roc_auc1 = metrics.auc(fpr1, tpr1)
# fpr1
# tpr1
# threshold1

# #roc and auc curve using matplotlib
# plt.title('ROC')
# plt.plot(fpr1, tpr1, 'b', label = 'AUC = %0.2f'% roc_auc1)
# plt.legend(loc = 'lower right')
# plt.plot([0,1], [0,1], 'r--')
# plt.xlim([0,1])
# plt.ylim([0,1])
# plt.xlabel('TPR')
# plt.ylabel('FPR')
# plt.show()